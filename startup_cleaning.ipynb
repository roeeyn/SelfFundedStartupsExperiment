{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def normalize_strings(string):\n",
    "    if isinstance(string, str):\n",
    "        return string\n",
    "    if math.isnan(string):\n",
    "        return None\n",
    "    raise Exception(\"not valid string\")\n",
    "\n",
    "def normalize_twitter_name(twitter_url):\n",
    "    if isinstance(twitter_url, str):\n",
    "        return re.split(r'twitter.com/', twitter_url)[-1].lower()\n",
    "    if math.isnan(twitter_url):\n",
    "        return None\n",
    "    raise Exception('not valid values for Twitter Handler')\n",
    "\n",
    "def normalize_url(url):\n",
    "    if isinstance(url, str):\n",
    "        main_domain = re.split(r'http(s)?://', url)[-1]\n",
    "        return f\"https://{main_domain}\"\n",
    "    if math.isnan(url):\n",
    "        return None\n",
    "    raise Exception(\"not valid url value\")\n",
    "    \n",
    "def normalize_category(category):\n",
    "    if category == \"1-10\":\n",
    "        return 1\n",
    "    if category == \"11-50\":\n",
    "        return 2\n",
    "    if category == \"51-200\":\n",
    "        return 3\n",
    "    if category == \"201-500\":\n",
    "        return 4\n",
    "    if category == \"501-1000\":\n",
    "        return 5\n",
    "    if category == \"1001-5000\":\n",
    "        return 6\n",
    "    if category == \"5001-10000\":\n",
    "        return 7\n",
    "    if category == \"10,001+\":\n",
    "        return 8\n",
    "    if math.isnan(category):\n",
    "        return None\n",
    "    raise Exception(\"not valid value for int category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"starter_startup.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Company name\"] = data[\"Company name\"].str.strip()\n",
    "data[\"Company Twitter\"] = data[\"Company Twitter\"].apply(normalize_twitter_name)\n",
    "data[\"employees_amount_id\"] = data[\"Nb. of Employees\"].apply(normalize_category)\n",
    "data[\"Nb. of Employees\"] = data[\"Nb. of Employees\"].astype('category')\n",
    "data[\"What do they do (Verbatim - 10 words max.)   \"]\n",
    "data[\"Link to website\"] = data[\"Link to website\"].apply(normalize_url)\n",
    "data[\"HQ City\"] = data[\"HQ City\"].apply(normalize_strings) # Should be left as it is, and later use a postal code better\n",
    "data[\"HQ Country\"] = data[\"HQ Country\"].apply(normalize_strings)# Should be left as it is, and later use the postal code and a geoposition API to get the Country\n",
    "data[\"CEO name\"] = data[\"CEO name\"].str.title()\n",
    "data[\"CEO's Twitter\"] = data[\"CEO's Twitter\"].apply(normalize_twitter_name)\n",
    "data[\"Link to jobpage\"] = data[\"Link to jobpage\"].apply(normalize_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./clean_startups.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
